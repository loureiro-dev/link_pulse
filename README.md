# WhatsApp Link Intelligence â€” Projeto Pessoal de Estudo ğŸš€


- Aprender e aplicar scraping avanÃ§ado (Requests + BeautifulSoup + Selenium).
- Criar um pipeline de dados que seja fÃ¡cil de entender, mas completo.
- Armazenar links coletados em um banco SQLite simples.
- Construir um minidashboard para visualizar resultados.
- Treinar habilidades Ãºteis para Data Science e Engenharia de Dados.
- E claro, automatizar algo que eu jÃ¡ fazia manualmente  ~E

---
# ğŸš€ WhatsApp Link Intelligence

Um projeto pessoal criado para automatizar um problema real do dia a dia:
monitorar links de grupos do WhatsApp escondidos em pÃ¡ginas de lanÃ§amento.

Com o tempo percebi que muitos produtores digitais escondem esses links dentro de:
- HTML quebrado  
- scripts JS
- iframes
- campos invisÃ­veis
- redirecionamentos

Fazer isso manualmente era cansativo, entÃ£o transformei o processo em um mini pipeline:
**coletar â†’ limpar â†’ detectar â†’ armazenar â†’ visualizar â†’ notificar (opcional).**

Este projeto foi criado com o objetivo de:
- treinar habilidades de *data scraping*
- praticar engenharia de dados
- construir um dashboard real utilizando Streamlit
- consolidar boas prÃ¡ticas de projeto
- ter um case sÃ³lido para portfÃ³lio e currÃ­culo

---

# ğŸ§  O que este projeto faz

### âœ” Coleta links pÃºblicos de grupos de WhatsApp
Procura padrÃµes do tipo:

- `https://chat.whatsapp.com/...`
- `https://api.whatsapp.com/send?phone=...`

### âœ” Extrai e normaliza links escondidos  
Limpa, normaliza e valida somente links que realmente sÃ£o de **grupos**.

### âœ” Armazena tudo em um banco SQLite  
Sem complicaÃ§Ã£o: um arquivo `.db` dentro da pasta `data/`.

### âœ” Evita duplicatas automaticamente  
Mesmo que o link apareÃ§a vÃ¡rias vezes, sÃ³ 1 registro Ã© salvo.

### âœ” Dashboard Streamlit completo
Com:
- tabela de links coletados  
- filtros por campanha e data  
- grÃ¡ficos (linha e distribuiÃ§Ã£o por fontes)
- CRUD de pÃ¡ginas (adicionar, editar, excluir)
- importaÃ§Ã£o/exportaÃ§Ã£o CSV  
- botÃ£o **Executar Scraper Agora**  
- registro da Ãºltima execuÃ§Ã£o  
- seÃ§Ã£o de mÃ©tricas rÃ¡pidas  
- tema visual simples e amigÃ¡vel  

### âœ” NotificaÃ§Ã£o no Telegram (opcional)
Receba alertas sempre que novos links forem encontrados.

---

## ğŸ§± Estrutura do Projeto

```
src/
    collectors/        # MÃ³dulos de coleta (requests e selenium)
    processing/        # Limpeza e normalizaÃ§Ã£o de links
    storage/           # Banco de dados SQLite
    notifications/     # NotificaÃ§Ã£o via Telegram (opcional)
    pipeline.py        # Pipeline principal
dashboard/
    app.py             # Dashboard em Streamlit
notebooks/
    exploratory_analysis.ipynb
data/
    raw/               # HTML bruto (opcional)
    processed/         # CSV/Parquet (opcional)
```

---

## ğŸš€ Como usar

1. Crie um ambiente virtual:

```
python -m venv venv
source venv/bin/activate
```

2. Instale dependÃªncias:

```
pip install -r requirements.txt
```

3. Configure (opcional) variÃ¡veis de ambiente para Telegram:

```
export WL_TOKEN="seu_token"
export WL_CHAT_ID="seu_chat"
```

4. Execute o pipeline:

```
python -m src.pipeline
```

5. Rode o dashboard:

```
streamlit run dashboard/app.py
```

Como usar o painel
â• Adicionar pÃ¡ginas

No painel, use o formulÃ¡rio:

URL da landing page

Nome da campanha

Exemplo:

https://minhacaptura.com/inscricao
Nome da campanha: Workshop InteligÃªncia Digital

ğŸš€ Rodar o scraper

Clique no botÃ£o:
Iniciar Coleta

Ele vai:

visitar todas as pÃ¡ginas cadastradas

extrair possÃ­veis links

filtrar apenas WhatsApp vÃ¡lidos

salvar no banco

atualizar o dashboard

ğŸ“ Exportar/Importar CSV

Ideal para organizar campanhas maiores.

---

## ğŸ“Œ Algumas limitaÃ§Ãµes (sim, existem!)

- PÃ¡ginas com **recaptcha** ainda travam o scraper.
- Alguns links aparecem apenas apÃ³s fluxos complexos (multi-step), e ainda nÃ£o implementei tudo.
- Em ambientes sem Chrome/Chromedriver, o Selenium pode nÃ£o funcionar.
- A heurÃ­stica de â€œpÃ¡gina de obrigadoâ€ Ã© simples â€” aceita sugestÃµes!

---

## ğŸ§  Ideias futuras

- Implementar coleta distribuÃ­da.
- Exportar tudo para um data lake (S3/MinIO).
- Criar modelo para prever quais pÃ¡ginas tÃªm maior chance de esconder grupos.
- Melhorar parser de JavaScript.

Se quiser contribuir, fique Ã  vontade ğŸ™‚  
